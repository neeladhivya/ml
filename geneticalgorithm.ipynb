{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dcb78ab2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Genetic Algorithm Best Route: [(0, 0), (7, 2), (4, 8), (3, 5), (0, 0)]\n",
      "Genetic Algorithm Best Distance: 22.981543376793567\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    " \n",
    "\n",
    "points = [(0, 0), (3, 5), (7, 2), (4, 8)]\n",
    "num_points = len(points)\n",
    " \n",
    "\n",
    "def distance(p1, p2):\n",
    "    return np.sqrt((p1[0] - p2[0])**2 + (p1[1] - p2[1])**2)\n",
    " \n",
    "\n",
    "def total_distance(route):\n",
    "    dist = sum(distance(route[i], route[i + 1]) for i in range(len(route) - 1))\n",
    "    return dist + distance(route[-1], route[0]) \n",
    " \n",
    "\n",
    "def initialize_pop(size):\n",
    "    pop = []\n",
    "    for _ in range(size):\n",
    "        route = points[1:]  # Exclude start point (0,0)\n",
    "        random.shuffle(route)\n",
    "        pop.append([points[0]] + route + [points[0]])  \n",
    "    return pop\n",
    " \n",
    "\n",
    "def select_parent(pop):\n",
    "    tournament_size = 3\n",
    "    selected = random.sample(pop, tournament_size)\n",
    "    selected.sort(key=total_distance)\n",
    "    return selected[0] \n",
    " \n",
    "\n",
    "def crossover(parent1, parent2):\n",
    "    start, end = sorted(random.sample(range(1, num_points), 2))  \n",
    "    child = [None] * num_points\n",
    " \n",
    "    \n",
    "    child[start:end] = parent1[start:end]\n",
    " \n",
    "  \n",
    "    p2_index = 1\n",
    "    for i in range(1, num_points):\n",
    "        if child[i] is None:\n",
    "            while parent2[p2_index] in child:\n",
    "                p2_index += 1\n",
    "            child[i] = parent2[p2_index]\n",
    "    \n",
    "    return [points[0]] + child[1:] + [points[0]]\n",
    " \n",
    "\n",
    "def mutate(route, mutation_rate=0.2):\n",
    "    if random.random() < mutation_rate:\n",
    "        i, j = random.sample(range(1, num_points), 2)  \n",
    "        route[i], route[j] = route[j], route[i]\n",
    "    return route\n",
    " \n",
    "\n",
    "def genetic_algorithm(pop_size=100, generations=500, mutation_rate=0.2):\n",
    "    pop = initialize_pop(pop_size)\n",
    "    best_route = min(pop, key=total_distance)\n",
    " \n",
    "    for _ in range(generations):\n",
    "        new_pop = []\n",
    "        \n",
    "      \n",
    "        for _ in range(pop_size):\n",
    "            parent1 = select_parent(pop)\n",
    "            parent2 = select_parent(pop)\n",
    "            child = crossover(parent1, parent2)\n",
    "            child = mutate(child, mutation_rate)\n",
    "            new_pop.append(child)\n",
    " \n",
    "        pop = new_pop\n",
    "        current_best = min(pop, key=total_distance)\n",
    "        if total_distance(current_best) < total_distance(best_route):\n",
    "            best_route = current_best\n",
    " \n",
    "    return best_route, total_distance(best_route)\n",
    " \n",
    "\n",
    "best_ga_route, best_ga_distance = genetic_algorithm()\n",
    "print(\"Genetic Algorithm Best Route:\", best_ga_route)\n",
    "print(\"Genetic Algorithm Best Distance:\", best_ga_distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e8bec30c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Descent Optimized Route: [[0.         0.        ]\n",
      " [0.13963032 2.1396303 ]\n",
      " [6.1946306  1.1946306 ]\n",
      " [4.         8.        ]]\n",
      "Gradient Descent Best Distance: 24.36724\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    " \n",
    "\n",
    "points = np.array([(0, 0), (3, 5), (7, 2), (4, 8)], dtype=np.float32)\n",
    " \n",
    "\n",
    "def total_distance(route):\n",
    "    dist = np.sum(np.linalg.norm(route[:-1] - route[1:], axis=1))\n",
    "    return dist + np.linalg.norm(route[-1] - route[0]) \n",
    " \n",
    "\n",
    "def compute_gradient(route, step=0.01):\n",
    "    grad = np.zeros_like(route)\n",
    "    for i in range(1, len(route) - 1): \n",
    "        original_pos = route[i].copy()\n",
    "        route[i] += step\n",
    "        loss1 = total_distance(route)\n",
    "        route[i] -= 2 * step\n",
    "        loss2 = total_distance(route)\n",
    "        grad[i] = (loss1 - loss2) / (2 * step)  \n",
    "        route[i] = original_pos \n",
    "    return grad\n",
    " \n",
    "\n",
    "def gradient_descent(route, learning_rate=0.01, iterations=500):\n",
    "    for _ in range(iterations):\n",
    "        grad = compute_gradient(route)\n",
    "        route -= learning_rate * grad  \n",
    "    return route, total_distance(route)\n",
    " \n",
    "\n",
    "optimized_gd_route, best_gd_distance = gradient_descent(points.copy())\n",
    " \n",
    "print(\"Gradient Descent Optimized Route:\", optimized_gd_route)\n",
    "print(\"Gradient Descent Best Distance:\", best_gd_distance)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "178f794a",
   "metadata": {},
   "source": [
    "OBSERVATION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec43478c",
   "metadata": {},
   "source": [
    "Gradient descent is not optimizable for discrete problems and only for continuous points. When forced to run on such points, it doesnt give a optimized distance. Hence Genetic algorithm is more preferred for optimization problems."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
